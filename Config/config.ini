[Dataset]
kd_train_file = Dataset/small_data/small_data.json
ca_train_file = Dataset/small_data/small_data.json
kd_dev_file = Dataset/small_data/small_data.json
ca_dev_file = Dataset/small_data/small_data.json
kd_train_file_p = Dataset/small_data/small_data_p_srl.txt
kd_train_file_h = Dataset/small_data/small_data_p_srl.txt
ca_train_file_p = Dataset/small_data/small_data_p_srl.txt
ca_train_file_h = Dataset/small_data/small_data_p_srl.txt
kd_dev_file_p = Dataset/small_data/small_data_p_srl.txt
kd_dev_file_h = Dataset/small_data/small_data_p_srl.txt
ca_dev_file_p = Dataset/small_data/small_data_p_srl.txt
ca_dev_file_h = Dataset/small_data/small_data_p_srl.txt
embedding_file = Dataset/glove.840B.300d.txt

[Save]
save_dir = snapshot
save_pkl_path = %(save_dir)s/pkl
save_model_path = %(save_dir)s/model
save_vocab_path = %(save_dir)s/vocab
bert_model_pkl = %(save_dir)s/model/bert_model.pkl
nli_model_pkl = %(save_dir)s/model/nli_model.pkl
kd_train_data_word_pkl = %(save_dir)s/pkl/kd_train_word_data.pkl
ca_train_data_word_pkl = %(save_dir)s/pkl/ca_train_word_data.pkl
kd_dev_data_word_pkl = %(save_dir)s/pkl/kd_dev_word_data.pkl
ca_dev_data_word_pkl = %(save_dir)s/pkl/ca_dev_word_data.pkl
fact_word_src_vocab = %(save_dir)s/vocab/fact_word_src_vocab.pkl
fact_word_tag_vocab = %(save_dir)s/vocab/fact_word_tag_vocab.pkl
embedding_pkl = %(save_dir)s/pkl/embedding.pkl
train_word_data_iter = %(save_dir)s/pkl/train_word_data_iter.pkl
dev_word_data_iter = %(save_dir)s/pkl/dev_word_data_iter.pkl
test_word_data_iter = %(save_dir)s/pkl/test_word_data_iter.pkl
load_dir = new-parser-model
load_model_path = %(load_dir)s/model
load_vocab_path = %(load_dir)s/vocab

[Train]
use_cuda = False
epoch = 3
tra_batch_size = 4
test_batch_size = 4
use_lr_decay = False
clip_max_norm_use = False
test_interval = 1
early_stop = 10
shuffle = True
update_every = 1
scheduler_bert = False

[Model]
embedding_word_dim = 300
embedding_word_num = 56746
max_length = 512
srl_dim = 400
parser_dim = 768
bert_size = 1024
hidden_size = 300
dropout = 0.5
class_num = 2
learning_algorithm = adam
bert_lr = 0.00001
weight_decay = 1.0e-8
epsilon = 1e-12
patience = 5
factor = 0.9
pre_embedding = False
stride = 1
num_capsules = 9
correct_bias = False
tune_start_layer = 0
srl = False
parser = False
s_p = False
sp_flag = False
decay = .75
decay_steps = 1000
clip = 1.0
beta_1 = .9
beta_2 = .9

